{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/raaif/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/raaif/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/raaif/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The quick brown fox jumps over the lazy dog\n",
      "Sentence after synonym replacement: The quick brown play_a_trick_on jumping over the work-shy dog\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)  # Remove the original word from synonyms\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    replaced_sentence = words[:]\n",
    "    words_indexes = list(range(len(words)))\n",
    "    random.shuffle(words_indexes)\n",
    "    \n",
    "    replaced = 0\n",
    "    for i in words_indexes:\n",
    "        synonyms = get_synonyms(words[i])\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms)\n",
    "            replaced_sentence[i] = synonym\n",
    "            replaced += 1\n",
    "            if replaced >= n:  # Replace up to n words\n",
    "                break\n",
    "\n",
    "    return ' '.join(replaced_sentence)\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "replaced_sentence = synonym_replacement(sentence, 3)  # Replace up to 3 words\n",
    "print(\"Original sentence:\", sentence)\n",
    "print(\"Sentence after synonym replacement:\", replaced_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raaif/.local/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: A hungry man wants to eat a pizza from the local takeaway\n",
      "Back-translated text: A hungry man wants to eat a pizza from the corner to take away\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def back_translate(text, model_name_src_to_tgt, model_name_tgt_to_src):\n",
    "    # Initialize the tokenizer and model for source to target language\n",
    "    tokenizer_src_to_tgt = MarianTokenizer.from_pretrained(model_name_src_to_tgt)\n",
    "    model_src_to_tgt = MarianMTModel.from_pretrained(model_name_src_to_tgt)\n",
    "    \n",
    "    # Translate from source to target language\n",
    "    translated = model_src_to_tgt.generate(**tokenizer_src_to_tgt(text, return_tensors=\"pt\", padding=True))\n",
    "    \n",
    "    # Decode the translated text\n",
    "    tgt_text = tokenizer_src_to_tgt.decode(translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Initialize the tokenizer and model for target to source language\n",
    "    tokenizer_tgt_to_src = MarianTokenizer.from_pretrained(model_name_tgt_to_src)\n",
    "    model_tgt_to_src = MarianMTModel.from_pretrained(model_name_tgt_to_src)\n",
    "    \n",
    "    # Translate back from target to source language\n",
    "    back_translated = model_tgt_to_src.generate(**tokenizer_tgt_to_src(tgt_text, return_tensors=\"pt\", padding=True))\n",
    "    \n",
    "    # Decode the back-translated text\n",
    "    src_text = tokenizer_tgt_to_src.decode(back_translated[0], skip_special_tokens=True)\n",
    "    \n",
    "    return src_text\n",
    "\n",
    "# Example usage\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "text2 = \"A hungry man wants to eat a pizza from the local takeaway\"\n",
    "model_name_src_to_tgt = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "model_name_tgt_to_src = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "\n",
    "back_translated_text = back_translate(text2, model_name_src_to_tgt, model_name_tgt_to_src)\n",
    "print(\"Original text:\", text2)\n",
    "print(\"Back-translated text:\", back_translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: The quick brown fox jumps over the lazy dog\n",
      "With insertion noise: The quick brown fox jaumps over the lazy dog\n",
      "With deletion noise: The quick brown fox jups over the lazy dog\n",
      "With substitution noise: The quick brown fox jumps over the lazy dlg\n",
      "With random noise of all types: The quick brown fox jumps over the lazy dag\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def inject_noise(sentence, noise_type='all', noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Injects noise into a given sentence. The type of noise can be specified.\n",
    "    - sentence: The input sentence to which noise will be added.\n",
    "    - noise_type: The type of noise to add ('insert', 'delete', 'substitute', or 'all').\n",
    "    - noise_level: Fraction of characters to alter (between 0 and 1).\n",
    "    \"\"\"\n",
    "    # Function to insert noise: Randomly adds a character within a word\n",
    "    def insert_noise(word):\n",
    "        if len(word) > 1:  # Avoid inserting into very short words\n",
    "            insert_pos = random.randint(1, len(word)-1)  # Avoid inserting at the first position\n",
    "            insert_char = random.choice(string.ascii_lowercase)\n",
    "            return word[:insert_pos] + insert_char + word[insert_pos:]\n",
    "        return word\n",
    "\n",
    "    # Function to delete noise: Randomly removes a character from a word\n",
    "    def delete_noise(word):\n",
    "        if len(word) > 1:\n",
    "            delete_pos = random.randint(0, len(word)-1)\n",
    "            return word[:delete_pos] + word[delete_pos+1:]\n",
    "        return word\n",
    "\n",
    "    # Function to substitute noise: Replaces a character with a random character\n",
    "    def substitute_noise(word):\n",
    "        if len(word) > 1:\n",
    "            substitute_pos = random.randint(0, len(word)-1)\n",
    "            substitute_char = random.choice(string.ascii_lowercase)\n",
    "            return word[:substitute_pos] + substitute_char + word[substitute_pos+1:]\n",
    "        return word\n",
    "\n",
    "    noise_functions = {\n",
    "        'insert': insert_noise,\n",
    "        'delete': delete_noise,\n",
    "        'substitute': substitute_noise\n",
    "    }\n",
    "\n",
    "    words = sentence.split()\n",
    "    num_words_to_change = max(1, int(len(words) * noise_level))  # Ensure at least one word is changed\n",
    "    words_to_change = random.sample(words, num_words_to_change)\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in words_to_change:\n",
    "            if noise_type == 'all':\n",
    "                # Apply a random noise function\n",
    "                noise_func = random.choice(list(noise_functions.values()))\n",
    "                words[i] = noise_func(word)\n",
    "            else:\n",
    "                # Apply the specified noise function\n",
    "                words[i] = noise_functions[noise_type](word)\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "print(\"Original sentence:\", sentence)\n",
    "print(\"With insertion noise:\", inject_noise(sentence, 'insert'))\n",
    "print(\"With deletion noise:\", inject_noise(sentence, 'delete'))\n",
    "print(\"With substitution noise:\", inject_noise(sentence, 'substitute'))\n",
    "print(\"With random noise of all types:\", inject_noise(sentence, 'all'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
